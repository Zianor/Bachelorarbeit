{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import src.utils as utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from src.ml_statistical_features import load_data_as_dataframe, get_all_scores, get_rf_grid_params, get_lda_grid_params, get_dt_grid_params, get_mlp_grid_params, get_linear_svc_grid_params, eval_classifier_paper\n",
    "from src.notebook_md_utils import get_md_data_distribution_string, get_md_mean_accuracy_grid, get_md_test_accuracy_grid, get_md_confusion_matrix_grid\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "  table {margin-left: 0 !important;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "  table {margin-left: 0 !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data_as_dataframe(segment_length=10, overlap_amount=0, hr_threshold=15)\n",
    "x = data.iloc[:, 0:13]\n",
    "y = data['informative_hr']\n",
    "patient_id = data['patient_id']\n",
    "\n",
    "\n",
    "data['abs_error'] = np.abs(data['bcg_hr']-data['ecg_hr'])\n",
    "data['rel_error'] = 100/data['ecg_hr'] * data['abs_error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitten der Daten in G1 und G2\n",
    "\n",
    "## Labelverteilung\n",
    "\n",
    "### Im Paper:\n",
    "58% informativ\n",
    "\n",
    "42% nicht-informativ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Vorliegende Daten"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "50 % informativ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "50 % nicht-informativ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distribution = np.bincount(y)\n",
    "\n",
    "display(Markdown(\"### Vorliegende Daten\"))\n",
    "display(Markdown(\"%i %s informativ\" % (round(100/len(y)*distribution[1]), '%')))\n",
    "display(Markdown(\"%i %s nicht-informativ\" % (round(100/len(y)*distribution[0]), '%')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Gruppenverteilung\n",
    "Segmente zuf√§llig in 2 Gruppen unterteilt\n",
    "### Im Paper\n",
    "\n",
    "\n",
    "|   | informativ | nicht-informativ | gesamt    |   \n",
    "|:--|:--------- :|:----------------:|:---------:|\n",
    "| G1 |1296 (62%)  | 789 (38%)        | 2085 (57%)|\n",
    "| G2 |813 (53%)   | 733 (47%)        | 1546 (43%)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Vorliegende Daten"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "|   | informativ | nicht-informativ | gesamt    |\n",
       "|:--|:--------- :|:----------------:|:---------:|\n",
       "|G1 | 24402 (50%)  | 24452 (50%)| 48854 (57%)|\n",
       "|G2 | 18409 (50%)  | 18446 (50%)| 36855 (43%)|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_g1, x_g2, y_g1, y_g2 = train_test_split(x, y, test_size=0.43, random_state=1, stratify=y)\n",
    "\n",
    "display(Markdown(\"### Vorliegende Daten\"))\n",
    "display(Markdown(get_md_data_distribution_string(y_g1, y_g2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Coverage + Mean Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-Fold cross validation mean accuracy for G1 and G2\n",
    "\n",
    "### Im Paper\n",
    "\n",
    "(RF: ntrees=50, SVM: rbf kernel, NN: 50 hidden neuron)\n",
    "\n",
    "|    | RF    | SVM   | NN    | LDA   | DT    |\n",
    "|:---|:-----:|:-----:|:-----:|:-----:|:-----:|\n",
    "| G1 | 98.13 | 93.38 | 91.61 | 89.26 | 97.51 |\n",
    "| G2 | 92.30 | 90.49 | 85.89 | 79.37 | 89.39 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Vorliegende Daten"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| | LDA| DT| RF| MLP| SVM| \n",
       "|:--|:--:|:--:|:--:|:--:|:--:|\n",
       " | G1 |  58.56  |  57.69  |  63.52  |  61.33  |  61.00  | \n",
       " | G2 |  58.52  |  57.15  |  63.34  |  60.97  |  60.38  | "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paths_paper = ['LDA_paper_hr15', 'DT_paper_hr15', 'RF_paper_hr15', 'MLP_paper_hr15', 'SVC_paper_hr10']\n",
    "scores = get_all_scores(reconstruct=False, paths=paths_paper)\n",
    "\n",
    "\n",
    "display(Markdown(\"### Vorliegende Daten\"))\n",
    "display(Markdown(get_md_mean_accuracy_grid(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy results for testing G2 vs. G1 (Exp1) and testing G1 vs. G2 (Exp2)\n",
    "\n",
    "### Im Paper\n",
    "\n",
    "|      | RF    | SVM   | NN    | LDA   | DT    |\n",
    "|:-----|:-----:|:-----:|:-----:|:-----:|:-----:|\n",
    "| Exp1 | 100   | 94.44 | 92.28 | 89.40 | 97.51 |\n",
    "| Exp2 | 97.99 | 97.46 | 87.10 | 90.26 | 97.41 |\n",
    "| Mean | 98.995| 95.95 | 89.69 | 89.83 | 98.41 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Vorliegende Daten"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| | LDA| DT| RF| MLP| SVM| \n",
       "|:--|:--:|:--:|:--:|:--:|:--:|\n",
       " | Exp1 |  58.46  |  57.76  |  63.32  |  61.13  |  61.72  | \n",
       " | Exp2 |  58.59  |  57.28  |  63.15  |  61.37  |  61.12  | \n",
       " | Mean |  58.52 |  57.52 |  63.23 |  61.25 |  61.42 | "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(\"### Vorliegende Daten\"))\n",
    "display(Markdown(get_md_test_accuracy_grid(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix of random forest for Exp2\n",
    "\n",
    "### Im Paper\n",
    "\n",
    "|             |                  | Actual        |                  |\n",
    "|:------------|:----------------:|:-------------:|:----------------:|\n",
    "|             |                  | informativ    | nicht-informativ |\n",
    "|             |                  |               |                  |\n",
    "|**Predicted**| informativ       | 1270          | 26               |\n",
    "|             | nicht-informativ | 18            | 771              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Vorliegende Daten"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "||| Actual ||\n",
       "|:--|:--:|:--:|:--:|\n",
       "||| informativ | nicht-informativ |\n",
       "|||||\n",
       "|**Predicted**| informativ | 14839 | 8475 |\n",
       "|| nicht-informativ | 9563 | 15977 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf, _ = get_rf_grid_params()\n",
    "_, _, _, _, _, y_pred_rf, y_true = eval_classifier_paper(x, y, patient_id, clf=rf, grid_folder_name='RF_paper_hr15')\n",
    "conf_mat = confusion_matrix(y_true, y_pred_rf)\n",
    "\n",
    "display(Markdown(\"### Vorliegende Daten\"))\n",
    "display(Markdown(get_md_confusion_matrix_grid(conf_mat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Andere Klassifikatoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### LDA"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "||| Actual ||\n",
       "|:--|:--:|:--:|:--:|\n",
       "||| informativ | nicht-informativ |\n",
       "|||||\n",
       "|**Predicted**| informativ | 16666 | 12550 |\n",
       "|| nicht-informativ | 7736 | 11902 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lda, _ = get_lda_grid_params()\n",
    "_, _, _, _, _, y_pred_lda, y_true = eval_classifier_paper(x, y, patient_id, clf=lda, grid_folder_name='LDA_paper_hr15')\n",
    "conf_mat = confusion_matrix(y_true, y_pred_lda)\n",
    "\n",
    "display(Markdown(\"#### LDA\"))\n",
    "display(Markdown(get_md_confusion_matrix_grid(conf_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Decision Tree"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "||| Actual ||\n",
       "|:--|:--:|:--:|:--:|\n",
       "||| informativ | nicht-informativ |\n",
       "|||||\n",
       "|**Predicted**| informativ | 14118 | 10461 |\n",
       "|| nicht-informativ | 10284 | 13991 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt, _ = get_dt_grid_params()\n",
    "_, _, _, _, _, y_pred_dt, y_true = eval_classifier_paper(x, y, patient_id, clf=dt, grid_folder_name='DT_paper_hr15')\n",
    "conf_mat = confusion_matrix(y_true, y_pred_dt)\n",
    "\n",
    "display(Markdown(\"#### Decision Tree\"))\n",
    "display(Markdown(get_md_confusion_matrix_grid(conf_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp, _ = get_mlp_grid_params()\n",
    "_, _, _, _, _, y_pred_mlp, y_true = eval_classifier_paper(x, y, patient_id, clf=mlp, grid_folder_name='MLP_paper_hr15')\n",
    "conf_mat = confusion_matrix(y_true, y_pred_mlp)\n",
    "\n",
    "display(Markdown(\"#### MLP\"))\n",
    "display(Markdown(get_md_confusion_matrix_grid(conf_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm, _ = get_linear_svc_grid_params()\n",
    "_, _, _, _, _, y_pred_svm, y_true = eval_classifier_paper(x, y, patient_id, clf=svm, grid_folder_name='SVC_paper_hr10')\n",
    "conf_mat = confusion_matrix(y_true, y_pred_svm)\n",
    "\n",
    "display(Markdown(\"#### SVM\"))\n",
    "display(Markdown(get_md_confusion_matrix_grid(conf_mat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fehler nach RF Klassifizierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relativer Fehler der Herzrate bei als informativ annotierten Segmenten 6.75 %\n",
      "Absoluter Fehler der Herzrate bei als informativ annotierten Segmenten 4.58  bpm\n",
      "Anzahl Segmente mit NaN Fehler bei als informativ vorausgesagten Segmenten 0\n",
      "Relativer Fehler der Herzrate bei als nicht informativ annotierten Segmenten 29.17 %\n",
      "Absoluter Fehler der Herzrate bei als nicht informativ annotierten Segmenten 20.92  bpm\n",
      "Anzahl Segmente mit NaN Fehler bei als nicht informativ annotierten Segmenten 67\n",
      "\n",
      "\n",
      "Relativer Fehler der Herzrate bei als informativ vorausgesagten Segmenten 13.89 %\n",
      "Absoluter Fehler der Herzrate bei als informativ vorausgesagten Segmenten 9.40  bpm\n",
      "Anzahl Segmente mit NaN Fehler bei als informativ vorausgesagten Segmenten 0\n",
      "Relativer Fehler der Herzrate bei als nicht informativ vorausgesagten Segmenten 21.67 %\n",
      "Absoluter Fehler der Herzrate bei als nicht informativ vorausgesagten Segmenten 15.81  bpm\n",
      "Anzahl Segmente mit NaN Fehler bei als nicht informativ vorausgesagten Segmenten 67\n"
     ]
    }
   ],
   "source": [
    "test_set = data.loc[y_true.index]\n",
    "informativ_annotiert = test_set[test_set['informative_hr']]\n",
    "non_informativ_annotiert = test_set[test_set['informative_hr'] == False]\n",
    "non_informativ_annotiert = non_informativ_annotiert.replace([np.inf, -np.inf], np.nan)\n",
    "informativ_rf = test_set[y_pred_rf]\n",
    "informativ_rf = informativ_rf.replace([np.inf, -np.inf], np.nan)\n",
    "non_informative_rf = test_set[y_pred_rf == False]\n",
    "non_informative_rf = non_informative_rf.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "print(\"Relativer Fehler der Herzrate bei als informativ annotierten Segmenten %.2f %s\" % (informativ_annotiert['rel_error'].mean(), \"%\"))\n",
    "print(\"Absoluter Fehler der Herzrate bei als informativ annotierten Segmenten %.2f %s\" % (informativ_annotiert['abs_error'].mean(), \" bpm\") )\n",
    "print(\"Anzahl Segmente mit NaN Fehler bei als informativ vorausgesagten Segmenten %i\" % (informativ_annotiert['abs_error'].isna().sum()))\n",
    "print(\"Relativer Fehler der Herzrate bei als nicht informativ annotierten Segmenten %.2f %s\" % (non_informativ_annotiert['rel_error'].mean(), \"%\"))\n",
    "print(\"Absoluter Fehler der Herzrate bei als nicht informativ annotierten Segmenten %.2f %s\" % (non_informativ_annotiert['abs_error'].mean(), \" bpm\") )\n",
    "print(\"Anzahl Segmente mit NaN Fehler bei als nicht informativ annotierten Segmenten %i\" % (non_informativ_annotiert['abs_error'].isna().sum()))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Relativer Fehler der Herzrate bei als informativ vorausgesagten Segmenten %.2f %s\" % (informativ_rf['rel_error'].mean(), \"%\"))\n",
    "print(\"Absoluter Fehler der Herzrate bei als informativ vorausgesagten Segmenten %.2f %s\" % (informativ_rf['abs_error'].mean(), \" bpm\") )\n",
    "print(\"Anzahl Segmente mit NaN Fehler bei als informativ vorausgesagten Segmenten %i\" % (informativ_rf['abs_error'].isna().sum()))\n",
    "print(\"Relativer Fehler der Herzrate bei als nicht informativ vorausgesagten Segmenten %.2f %s\" % (non_informative_rf['rel_error'].mean(), \"%\"))\n",
    "print(\"Absoluter Fehler der Herzrate bei als nicht informativ vorausgesagten Segmenten %.2f %s\" % (non_informative_rf['abs_error'].mean(), \" bpm\") )\n",
    "print(\"Anzahl Segmente mit NaN Fehler bei als nicht informativ vorausgesagten Segmenten %i\" % (non_informative_rf['abs_error'].isna().sum()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
